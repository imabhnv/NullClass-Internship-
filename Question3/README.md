
# ğŸ¤– ArXiv Research Assistant Chatbot ğŸ“š

- [Live App](https://imabhnv-arxiv-chatbot.streamlit.app/)
- This project allows users to query a chatbot based on scientific papers related to computer science from the ArXiv dataset. The chatbot leverages NLP techniques, open-source LLMs, and Streamlit to provide answers and explanations.

## ğŸ” Project Workflow

### 1ï¸âƒ£ Preprocessing the ArXiv Dataset ğŸ§¹
The dataset used for this project is the `arxiv-metadata-oai-snapshot.json` file, which contains metadata of scientific papers. Before running the chatbot, we need to preprocess the dataset to filter out the relevant papers based on the field of computer science.

Run the following script to filter and preprocess the dataset:(Assuming you have downloaded the metadata file from Kaggle and saved in data folder)
```bash
python process_arxiv.py --input data/arxiv-metadata-oai-snapshot.json  --output data/output.json --domain cs --max_papers 1000
```
This will generate the `output.json` file ğŸ“„ containing the filtered papers relevant to computer science, which will be used for generating embeddings and querying by the chatbot.

### 2ï¸âƒ£ Optimizing CPU Memory ğŸ§ ğŸ’»
To efficiently use models on CPU, we have the `optimize_cpu.py` file that optimizes memory usage and helps in selecting models that are compatible with CPU. The following functions are included in this file:

- ğŸ”„ **optimize_memory**: Clears garbage collection and frees GPU memory cache (if any).
- ğŸ“Š **get_system_memory_info**: Fetches system memory info.
- ğŸ“¦ **get_embedding_batch_size**: Adjusts batch size for embeddings dynamically.
- ğŸ§  **load_optimized_embedding_model**: Loads SentenceTransformer for CPU.
- ğŸ§¬ **generate_embeddings_batched**: Efficient batch embedding generator.
- ğŸ¤– **load_optimized_llm**: Loads lightweight LLMs like `facebook/opt-125m`.
- âœ… **check_model_compatibility**: Checks CPU compatibility.

### 3ï¸âƒ£ Running the Chatbot Application ğŸš€ğŸ’¬
Once the dataset is preprocessed, the `app.py` file is used to run the chatbot application. This is a Streamlit-based web interface that interacts with the user, generates embeddings, retrieves relevant documents, and generates answers using a lightweight LLM.

Run the following command to start the application:
```bash
streamlit run app.py
```

The application will allow you to:
- ğŸ›ï¸ Select an LLM model from available options.
- ğŸ” Input a research topic or keyword.
- ğŸ“‘ Retrieve relevant papers from the dataset.
- ğŸ§  Summarize and explain the research topic.

## ğŸ“‚ File Overview
- `process_arxiv.py` ğŸ“„: Preprocesses ArXiv dataset.
- `optimize_cpu.py` âš™ï¸: Optimizes model usage on CPU.
- `app.py` ğŸ’¬: Main chatbot application with Streamlit.

## ğŸ“¦ Requirements
- Python 3.7+ ğŸ
- Required Libraries: 
  - pandas ğŸ“Š
  - numpy â•
  - torch ğŸ”¥
  - transformers ğŸ¤–
  - sentence-transformers ğŸ§ 
  - sklearn ğŸ“š
  - streamlit ğŸŒ
  - psutil ğŸ“ˆ

Install with:
```bash
pip install -r requirements.txt
```

## ğŸ“ Notes
- âœ… Make sure you have access to the ArXiv dataset.
- ğŸ“ˆ Chatbot quality depends on embeddings and LLM.
- ğŸ’¾ 8GB+ RAM recommended for smooth experience.
- ğŸ’» Three different models can generate different results from each other.
- ğŸ˜ I also tried to add relevant emojis and comments in files.

## Made with ğŸ’»â™¥ï¸ by Abhinav VarshneyğŸš€
---
